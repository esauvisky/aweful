{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "from math import ceil, floor\n",
    "import shutil\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import random\n",
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import deque\n",
    "from concurrent.futures import (ProcessPoolExecutor, ThreadPoolExecutor, as_completed)\n",
    "\n",
    "import cupy as cp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import mixed_precision\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import ConvLSTM2D, Dense, Flatten, Input, MaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, image_utils\n",
    "from loguru import logger\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.autonotebook import tqdm\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Define default hyperparameters\n",
    "SEQUENCE_LENGTH = 16\n",
    "IMAGE_HEIGHT = 480 // 10\n",
    "IMAGE_WIDTH = 640 // 10\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "PATIENCE = 5\n",
    "DEBUG = False\n",
    "FILENAME = f'weights-{SEQUENCE_LENGTH}_{IMAGE_HEIGHT}_{IMAGE_WIDTH}.h5'\n",
    "\n",
    "\n",
    "def setup_logging(level=\"DEBUG\", show_module=False):\n",
    "    \"\"\"\n",
    "    Setups better log format for loguru\n",
    "    \"\"\"\n",
    "    # logger.remove(0)    # Remove the default logger\n",
    "    log_level = level\n",
    "    log_fmt = u\"<green>[\"\n",
    "    log_fmt += u\"{file:10.10}â€¦:{line:<3} | \" if show_module else \"\"\n",
    "    log_fmt += u\"{time:HH:mm:ss.SSS}]</green> <level>{level: <8}</level> | <level>{message}</level>\"\n",
    "    logger.add(sys.stderr, level=log_level, format=log_fmt, colorize=True, backtrace=True, diagnose=True)\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    \"\"\"Create a ConvLSTM model.\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = ConvLSTM2D(filters=2, kernel_size=(5, 5), activation=\"tanh\", recurrent_dropout=0.2, return_sequences=True)(inputs)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4, activation=\"relu\")(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "    out_model = Model(inputs=inputs, outputs=outputs)\n",
    "    out_model.summary()\n",
    "    return out_model\n",
    "\n",
    "\n",
    "def create_wandb_images_table():\n",
    "    columns = ['Index', 'Date', 'Prediction']\n",
    "    for s in range(SEQUENCE_LENGTH):\n",
    "        columns.append(f'Sample {s + 1}')\n",
    "    return wandb.Table(columns=columns, allow_mixed_types=True)\n",
    "\n",
    "\n",
    "def create_wandb_predictions_table():\n",
    "    columns = ['Index', 'Date', 'Prediction']\n",
    "    return wandb.Table(columns=columns, allow_mixed_types=True)\n",
    "\n",
    "\n",
    "class CustomBatchEndCallback(Callback):\n",
    "    def __init__(self, X, y, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.test_table = create_wandb_images_table()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        super().on_train_batch_end(batch, logs)\n",
    "        if batch % random.randrange(8, 15) == 0:\n",
    "            # Get the X value (array of images) for the first sample in the batch\n",
    "            X_step = self.X[batch * BATCH_SIZE]\n",
    "            y_step = \"Sleep\" if self.y[batch * BATCH_SIZE] == 1 else \"Awake\"\n",
    "\n",
    "            # create a table with each image of the sequence\n",
    "            images = []\n",
    "            for sequence_ix, _img in enumerate(X_step):\n",
    "                # image is the same as self.x_train[batch_ix * BATCH_SIZE + ix][0]\n",
    "                img = wandb.Image(_img, caption=f\"Image {batch * BATCH_SIZE + sequence_ix} - Label: {y_step}\")\n",
    "                images.append(img)\n",
    "\n",
    "            # Adds the row to the table with the actual index of the first image of the sequence,\n",
    "            # the original label y, and the images\n",
    "            date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            self.test_table.add_data(batch * BATCH_SIZE, date, y_step, *images)\n",
    "            print(f\" | Samples {batch * BATCH_SIZE}-{batch * BATCH_SIZE + SEQUENCE_LENGTH - 1} - Label: {y_step})'\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        wandb.log({\"data\": self.test_table}, commit=True)\n",
    "        self.test_table = create_wandb_images_table()\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "\n",
    "\n",
    "def get_random_crop(image, seed=None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    aspect_ratio = float(width) / float(height)\n",
    "\n",
    "    if width > height:\n",
    "        new_width = np.random.randint(int(width * 0.7), width)\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    else:\n",
    "        new_height = np.random.randint(int(height * 0.7), height)\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "\n",
    "    x = np.random.randint(0, width - new_width)\n",
    "    y = np.random.randint(0, height - new_height)\n",
    "\n",
    "    crop = image[y:y + new_height, x:x + new_width]\n",
    "    resized_crop = cv2.resize(crop, (width, height))\n",
    "    resized_crop = np.expand_dims(resized_crop, axis=-1) # Add an extra channel dimension\n",
    "    return resized_crop\n",
    "\n",
    "\n",
    "def get_image(image_path, image_height, image_width):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = image[0:image.shape[0], 0:image.shape[1] - 21]\n",
    "    image = cv2.resize(image, (image_width, image_height))\n",
    "    image = np.expand_dims(image, axis=-1) # Add an extra channel dimension\n",
    "    return image\n",
    "\n",
    "\n",
    "def process_image_sequence(image_files, images_path, image_height, image_width):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for file in image_files:\n",
    "        image = get_image(os.path.join(images_path, file), image_height, image_width)\n",
    "        label = 1 if \"sleep\" in file else 0\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    return images, labels[-1]\n",
    "\n",
    "\n",
    "def load_data(images_path, seq_length, image_height, image_width):\n",
    "    X, y = [], []\n",
    "\n",
    "    # Get the list of image files\n",
    "    image_files = sorted((file for file in os.listdir(images_path) if file.endswith(\".jpg\")),\n",
    "                         key=lambda x: int(x.split(\".\")[0].split(\"-\")[0]))\n",
    "\n",
    "    # Use a ThreadPoolExecutor to process image sequences in parallel\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        # Create the tqdm progress bar\n",
    "        progress_bar = tqdm(\n",
    "            total=len(image_files) - seq_length,\n",
    "            smoothing=0.1,\n",
    "            desc=\"Processing images...\",\n",
    "        )\n",
    "\n",
    "        # Submit the tasks to the executor\n",
    "        futures = [\n",
    "            executor.submit(process_image_sequence, image_files[i:i + seq_length], images_path, image_height, image_width)\n",
    "            for i in range(0,\n",
    "                           len(image_files) - seq_length)]\n",
    "\n",
    "        # Use as_completed() to process the results as they become available, and update the progress bar\n",
    "        for future in as_completed(futures):\n",
    "            images, label = future.result()\n",
    "            X.append(images)\n",
    "            y.append(label)\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "    logger.info(\"Data loaded.\")\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def set_mixed_precision():\n",
    "    # Enable mixed precision training\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 13:18:42.017 | INFO     | __main__:<module>:4 - Num GPUs Available: 1\n",
      "\u001b[32m[13:18:42.017]\u001b[0m \u001b[1mINFO    \u001b[0m | \u001b[1mNum GPUs Available: 1\u001b[0m\n",
      "\u001b[32m[13:18:42.017]\u001b[0m \u001b[1mINFO    \u001b[0m | \u001b[1mNum GPUs Available: 1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bz54s6tl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-jazz-65</strong> at: <a href='https://wandb.ai/esauvisky/aweful-train/runs/bz54s6tl' target=\"_blank\">https://wandb.ai/esauvisky/aweful-train/runs/bz54s6tl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230412_130933-bz54s6tl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:bz54s6tl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e24513f7591486d95e5f9622721a6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668139200191945, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/emi/Coding/aweful/wandb/run-20230412_131842-ujnw8n4c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esauvisky/aweful-train/runs/ujnw8n4c' target=\"_blank\">wandering-sky-66</a></strong> to <a href='https://wandb.ai/esauvisky/aweful-train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esauvisky/aweful-train' target=\"_blank\">https://wandb.ai/esauvisky/aweful-train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esauvisky/aweful-train/runs/ujnw8n4c' target=\"_blank\">https://wandb.ai/esauvisky/aweful-train/runs/ujnw8n4c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/esauvisky/aweful-train/runs/ujnw8n4c?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0a18295210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "routine = \"train\"\n",
    "\n",
    "setup_logging(\"DEBUG\" if DEBUG else \"INFO\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "set_mixed_precision()\n",
    "\n",
    "# # start a new wandb run to track this script\n",
    "wandb.init(project=f\"aweful-{routine}\",\n",
    "            config={\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"loss\": \"binary_crossentropy\",\n",
    "                \"metric\": \"accuracy\",\n",
    "                \"epoch\": EPOCHS,\n",
    "                \"batch_size\": BATCH_SIZE,})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images...:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5318/13835 [00:22<00:33, 250.58it/s]"
     ]
    }
   ],
   "source": [
    "if routine == \"train\" or routine == \"check\":\n",
    "    with tf.device(\"GPU\"):\n",
    "        X, y = load_data(\"./data/0\", SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "    # Split the data\n",
    "    # indices = np.random.permutation(len(X)).tolist()\n",
    "    # X_train, y_train = X[indices], y[indices]\n",
    "    # X_val, y_val = X[indices], y[indices]\n",
    "    X_train = np.concatenate((X[:int(len(X) * 0.5)], X[int(len(X) * 0.7):]), axis=0)\n",
    "    y_train = np.concatenate((y[:int(len(y) * 0.5)], y[int(len(y) * 0.7):]), axis=0)\n",
    "    X_val = X[int(len(X) * 0.5):int(len(X) * 0.7)]\n",
    "    y_val = y[int(len(y) * 0.5):int(len(y) * 0.7)]\n",
    "\n",
    "# Create the ConvLSTM model\n",
    "input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(generator, X, y):\n",
    "    return tf.data.Dataset.from_generator(generator=generator,\n",
    "                                          args=(X, y, BATCH_SIZE),\n",
    "                                          output_types=(tf.float16, tf.int8),\n",
    "                                          output_shapes=(\n",
    "                                              (BATCH_SIZE, SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 1),\n",
    "                                              (BATCH_SIZE,),\n",
    "                                          ))\n",
    "                                        #   )).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "def data_generator(X, y, batch_size):\n",
    "    num_samples = len(X)\n",
    "    datagen = ImageDataGenerator(rotation_range=10)\n",
    "\n",
    "    # real_batch_size = ceil(batch_size / 2)\n",
    "    # batch_size = floor(batch_size / 2)\n",
    "    while True:\n",
    "        # Generate batches of data\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            if start + batch_size > num_samples:\n",
    "                break\n",
    "            end = start + batch_size\n",
    "            X_batch = X[start:end]\n",
    "            y_batch = y[start:end]\n",
    "            seed = random.randint(0, 1000)\n",
    "\n",
    "            # Data augmentation\n",
    "            # X_batch_aug = []\n",
    "            # for i in range(batch_size):\n",
    "            #     image_sequence = X_batch[i]\n",
    "            #     augmented_sequence = []\n",
    "            #     for image in image_sequence:\n",
    "            #         transformed = datagen.random_transform(image, seed=seed)\n",
    "            #         cropped = get_random_crop(transformed, seed=seed)\n",
    "            #         augmented_sequence.append(cropped)\n",
    "            #     X_batch_aug.append(augmented_sequence)\n",
    "\n",
    "            # X_batch_aug = cp.array(X_batch_aug)\n",
    "            X_batch = cp.array(X_batch, dtype=cp.float16)\n",
    "            y_batch = cp.array(y_batch, dtype=cp.int8)\n",
    "            cp.divide(X_batch, 255.0, out=X_batch, dtype=cp.float16, casting=\"unsafe\")\n",
    "            # cp.divide(X_batch_aug, 255.0, out=X_batch_aug, dtype=cp.float16, casting=\"unsafe\")\n",
    "            # X_batch = cp.concatenate((X_batch, X_batch_aug), axis=0)\n",
    "            # y_batch = cp.concatenate((y_batch, y_batch), axis=0)\n",
    "            # X_batch = cp.asnumpy(X_batch)\n",
    "            # y_batch = cp.asnumpy(y_batch)\n",
    "            yield X_batch.get(), y_batch.get()\n",
    "\n",
    "\n",
    "if routine == \"train\":\n",
    "    with tf.device(\"CPU\"):\n",
    "        train_dataset = get_generator(data_generator, X_train, y_train)\n",
    "        val_dataset = get_generator(data_generator, X_val, y_val)\n",
    "\n",
    "    # Compute the number of steps per epoch\n",
    "    steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "    validation_steps = len(X_val) // BATCH_SIZE\n",
    "    data_generator(X_train, y_train, BATCH_SIZE)\n",
    "\n",
    "    with tf.device(\"GPU\"):\n",
    "        callbacks = [\n",
    "            CustomBatchEndCallback(X, y),\n",
    "            WandbCallback(log_weights=True,\n",
    "                            log_evaluation=True,\n",
    "                            log_batch_frequency=10,\n",
    "                            log_evaluation_frequency=10,\n",
    "                            log_weights_frequency=10,\n",
    "                            save_model=False),\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "            ModelCheckpoint(FILENAME, monitor=\"val_loss\", save_best_only=True, verbose=1)]\n",
    "\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=callbacks,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=val_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "        )\n",
    "    logger.info(\"Finished training\")\n",
    "\n",
    "    # Save the model weights\n",
    "    model.save_weights(FILENAME)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.round(y_pred)\n",
    "\n",
    "    # Evaluate the model performance\n",
    "    logger.info(\"\\nConfusion matrix:\\n\" + str(confusion_matrix(y_val, y_pred_classes)))\n",
    "    logger.info(\"\\nClassification report:\\n\" + str(classification_report(y_val, y_pred_classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(FILENAME):\n",
    "    model.load_weights(FILENAME)\n",
    "    logger.success(f\"Loaded model weights from {FILENAME}\")\n",
    "else:\n",
    "    logger.error(f\"Could not find file '{FILENAME}'\")\n",
    "    if routine != \"train\": \n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if routine == \"check\":\n",
    "    with tf.device(\"CPU\"):\n",
    "        X_predict = tf.data.Dataset.from_generator(generator=data_generator,\n",
    "                                                    args=(X),\n",
    "                                                    output_types=(tf.float16, tf.int8),\n",
    "                                                    output_shapes=(\n",
    "                                                        (BATCH_SIZE, SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 1),\n",
    "                                                    ))\n",
    "                                                #    )).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        y_out = model.predict(X_predict, verbose=1)\n",
    "        y_out = np.round(y_out).flatten().astype(int)\n",
    "        for n, cat in enumerate(y_out):\n",
    "            prediction = \"ðŸ†™\" if cat == 0 else \"ðŸ’¤\"\n",
    "            # if y_predict[n] != cat: color = \"\\033[91m\"\n",
    "            color = \"\\033[92m\" if cat == 0 else \"\\033[93m\"\n",
    "            print(color + f\"{i:05d}:\" + str(prediction) + \"\\033[0m\", end=\" | \")\n",
    "    # for i in range(0, len(X), BATCH_SIZE):\n",
    "    #     X_predict = X[i:i + BATCH_SIZE]\n",
    "    #     y_predict = y[i:i + BATCH_SIZE]\n",
    "    #     y_out = model.predict(X_predict, verbose=0)\n",
    "    #     y_out = np.round(y_out).flatten().astype(int)\n",
    "    #     for n, cat in enumerate(y_out):\n",
    "    #         prediction = \"ðŸ†™\" if cat == 0 else \"ðŸ’¤\"\n",
    "    #         if y_predict[n] != cat: color = \"\\033[91m\"\n",
    "    #         else: color = \"\\033[92m\" if cat == 0 else \"\\033[93m\"\n",
    "    #         print(color + f\"{i:05d}:\" + str(prediction) + \"\\033[0m\", end=\" | \")\n",
    "    routine = \"clock\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if routine == \"clock\":\n",
    "    index = 0\n",
    "    # get the latest used index number\n",
    "    for group in os.listdir(\"./data\"):\n",
    "        for filename in os.listdir(\"./data/\" + group):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                num = int(filename.split(\".\")[0].split(\"-\")[0])\n",
    "                if num >= index:\n",
    "                    index = num + 1\n",
    "\n",
    "    sleep_counter = deque(maxlen=6 * 60)\n",
    "    images = deque(maxlen=SEQUENCE_LENGTH)\n",
    "    path = f\"./data/{int(group) + 1}/\"\n",
    "\n",
    "    while True:\n",
    "        subprocess.run(shlex.split(f\"fswebcam /tmp/aweful_tmp.jpg -d /dev/video0 -S2 -F1\"),\n",
    "                        check=False,\n",
    "                        stdout=subprocess.DEVNULL,\n",
    "                        stderr=subprocess.DEVNULL)\n",
    "\n",
    "        image = get_image(f\"/tmp/aweful_tmp.jpg\", IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "        images.append(image)\n",
    "        # # image = image_utils.load_img(f\"{path}{index}.jpg\", color_mode=\"grayscale\")\n",
    "        # # image = image_utils.img_to_array(image)\n",
    "        # # image = image[:-21, :]\n",
    "\n",
    "        # resized = image_utils.array_to_img(image).resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        # resized = image_utils.img_to_array(resized, dtype=np.float16) / 255.0\n",
    "        # images.append(resized)\n",
    "\n",
    "        if len(images) < SEQUENCE_LENGTH:\n",
    "            # sleep_counter.append(0)\n",
    "            # logger.info(f\"No sleep detected {sleep_counter.count(1)} / {len(sleep_counter)}\")\n",
    "            continue\n",
    "\n",
    "        X_loop = np.array([images], dtype=np.float16)\n",
    "        y_loop = model.predict(X_loop, verbose=0)\n",
    "        y_loop_class = np.round(y_loop).flatten().astype(int)[0]\n",
    "\n",
    "        date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        prediction = \"Awake ðŸ†™\" if y_loop_class == 0 else \"Sleep ðŸ’¤\"\n",
    "\n",
    "        if y_loop_class == 1:\n",
    "            sleep_counter.append(1)\n",
    "            logger.warning(f\"Sleep detected {sleep_counter.count(1)} / {len(sleep_counter)}\")\n",
    "        else:\n",
    "            sleep_counter.append(0)\n",
    "            logger.info(f\"No sleep detected {sleep_counter.count(1)} / {len(sleep_counter)}\")\n",
    "\n",
    "        index += 1\n",
    "        # copy the image to the data folder\n",
    "        shutil.copy(\"/tmp/aweful_tmp.jpg\", f'{path}{index}-{\"awake\" if y_loop_class == 0 else \"sleep\"}.jpg')\n",
    "\n",
    "        if sleep_counter.count(1) > 0.8 * 6 * 60:\n",
    "            print(\"Wake up! You've been sleeping for more than 6 hours!\")\n",
    "            alarm_triggered = True\n",
    "        else:\n",
    "            alarm_triggered = False\n",
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
